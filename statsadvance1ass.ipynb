{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 1. Explain the properties of the F-distribution."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### The F-distribution is fundamental in hypothesis testing, especially in comparing variances or testing the overall significance of regression models. Key properties include:\n",
    "\n",
    "1. **Positivity**: The F-distribution only takes non-negative values because it represents a ratio of variances (both non-negative quantities).\n",
    "\n",
    "2. **Asymmetry**: It is positively skewed, with a longer tail on the right. This means large F-values are less frequent but possible, reflecting large differences between variances.\n",
    "\n",
    "3. **Shape Dependence on Degrees of Freedom**:\n",
    "   - The shape of the F-distribution is determined by two parameters: the degrees of freedom for the numerator (\\(df_1\\)) and denominator (\\(df_2\\)).\n",
    "   - For smaller degrees of freedom, the distribution is more skewed. As \\(df_1\\) and \\(df_2\\) increase, it approaches a normal distribution.\n",
    "\n",
    "4. **Mean and Variance**:\n",
    "\n",
    "   - Mean: For \\(df_2 > 2\\), the mean of the F-distribution is \\( \\mu = \\frac{df_2}{df_2 - 2} \\).\n",
    "   - Variance: For \\(df_2 > 4\\), the variance is \\( \\text{Var} = \\frac{2(df_2^2)(df_1 + df_2 - 2)}{df_1(df_2 - 2)^2(df_2 - 4)} \\).\n",
    "\n",
    "5. **Applications**: Commonly used in ANOVA, regression analysis, and variance comparison tests.\n",
    "\n",
    "Example: \n",
    "If the variance in a sample is significantly larger than another, the F-statistic will be greater than 1, with extreme values potentially leading to rejecting the null hypothesis."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 2. In which types of statistical tests is the F-distribution used, and why is it appropriate for these tests?"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### **Answer**\n",
    "The F-distribution is widely applied in tests involving ratios of variances. These include:\n",
    "\n",
    "1. **ANOVA (Analysis of Variance)**:\n",
    "   - Used to compare the means of more than two groups.\n",
    "   - The F-distribution is suitable because it evaluates whether the variance between group means is significantly greater than the variance within groups.\n",
    "\n",
    "2. **F-tests for Variance Comparison**:\n",
    "   - Compares the variances of two independent populations.\n",
    "   - The F-statistic is a ratio of two sample variances, making the F-distribution appropriate.\n",
    "\n",
    "3. **Regression Analysis**:\n",
    "   - Assesses the overall significance of a regression model.\n",
    "   - Tests if the variation explained by the model is significant compared to unexplained variation.\n",
    "\n",
    "Why appropriate?:\n",
    "- The F-distribution models the variability expected in sample variances under the null hypothesis, providing a theoretical framework for these tests."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 3. Key assumptions required for conducting an F-test to compare the variances of two populations."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "vscode": {
     "languageId": "markdown"
    }
   },
   "source": [
    "### **Answer**\n",
    "Key assumptions required for conducting an F-test to compare the variances of two populations:\n",
    "\n",
    "1. **Normality**: Both populations should be normally distributed.\n",
    "2. **Independence**: The samples must be independent of each other.\n",
    "3. **Random Sampling**: Data should be collected through random sampling.\n",
    "4. **Scale of Measurement**: Data should be measured on an interval or ratio scale.\n",
    "\n",
    "Violations of these assumptions can affect the validity of the F-test. If assumptions are not met, consider alternative tests such as Levene's test.\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 4. Purpose of ANOVA and how it differs from a t-test."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### **Answer**\n",
    "**Purpose of ANOVA**:\n",
    "ANOVA (Analysis of Variance) is used to test for significant differences among group means when there are more than two groups. It evaluates whether observed differences are likely due to true differences or random chance.\n",
    "\n",
    "**How ANOVA differs from a t-test**:\n",
    "1. **Number of Groups**:\n",
    "   - t-test: Compares the means of two groups only.\n",
    "   - ANOVA: Compares the means of three or more groups simultaneously.\n",
    "\n",
    "2. **Error Control**:\n",
    "   - Conducting multiple t-tests increases the risk of Type I error (false positives).\n",
    "   - ANOVA controls this risk by testing all groups together.\n",
    "\n",
    "3. **Hypotheses**:\n",
    "   - t-test: Null hypothesis states the means of two groups are equal.\n",
    "   - ANOVA: Null hypothesis states that all group means are equal (no significant difference among them).\n",
    "\n",
    "**Example:**\n",
    "If we want to compare the test scores of students across three schools, ANOVA is more efficient and statistically valid than conducting multiple t-tests."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 5. Why use a one-way ANOVA instead of multiple t-tests for comparing more than two groups?"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### **Answer**\n",
    "**Reasons for using one-way ANOVA instead of multiple t-tests:**\n",
    "\n",
    "1. **Type I Error Control**: Performing multiple t-tests increases the probability of making a Type I error (false positive). ANOVA controls the overall error rate by testing all groups simultaneously.\n",
    "\n",
    "2. **Efficiency**: ANOVA provides a single test to determine if there are any significant differences among group means, rather than requiring multiple pairwise comparisons.\n",
    "\n",
    "3. **Interpretability**: ANOVA gives an overall assessment of group differences, making it easier to interpret results when comparing more than two groups.\n",
    "\n",
    "**Example**: If we have four groups and perform all possible t-tests, we would conduct six tests, increasing the chance of incorrectly finding a significant difference. One-way ANOVA avoids this problem by using a single test.\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 6. Variance partitioning in ANOVA and its role in F-statistic calculation."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### **Answer:**\n",
    "**Variance Partitioning in ANOVA**:\n",
    "ANOVA divides the total variability in the data into two components:\n",
    "1. **Between-group variance**:\n",
    "   - Measures the variability due to differences in group means.\n",
    "   - Represents the variability explained by the grouping factor.\n",
    "\n",
    "2. **Within-group variance**:\n",
    "   - Measures the variability within each group (unexplained variability).\n",
    "   - Represents the natural variation in the data.\n",
    "\n",
    "\n",
    "**Role in F-statistic Calculation:**\n",
    "\n",
    "The F-statistic is the ratio of between-group variance to within-group variance:\n",
    "\n",
    "$$\n",
    "F = \\frac{\\text{Between-group variance} / (k - 1)}{\\text{Within-group variance} / (n - k)}\n",
    "$$\n",
    "\n",
    "where \\(k\\) is the number of groups and \\(n\\) is the total number of observations.\n",
    "\n",
    "\n",
    "\n",
    "- A large F-value indicates that the between-group variance is much larger than the within-group variance, suggesting significant differences between group means.\n",
    "- A small F-value implies that the differences between group means are not larger than expected by chance.\n",
    "\n",
    "Example:\n",
    "Consider testing the effectiveness of three teaching methods. ANOVA evaluates whether the variation in test scores is due to the teaching methods (between-group) or random variation (within-group).\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 7. Comparison of classical (frequentist) and Bayesian approaches to ANOVA."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Answer:\n",
    "Key differences:\n",
    "1. Handling uncertainty:\n",
    "   - Frequentist: Relies on sampling distributions and p-values.\n",
    "   - Bayesian: Uses probability distributions to express uncertainty.\n",
    "2. Parameter estimation:\n",
    "   - Frequentist: Estimates parameters based on likelihood and sample data.\n",
    "   - Bayesian: Combines prior information with data likelihood for posterior estimates.\n",
    "3. Hypothesis testing:\n",
    "   - Frequentist: Tests null hypotheses with fixed criteria (e.g., p-values).\n",
    "   - Bayesian: Provides probabilities for hypotheses (e.g., Bayes factors).\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 8. F-test for variance equality."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "F-statistic: 2.089171974522293\n",
      "p-value: 0.24652429950266966\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "'\\nInterpretation:\\n- If the p-value < 0.05 (common significance level), reject the null hypothesis that the variances are equal.\\n- Otherwise, fail to reject the null hypothesis, implying variances are not significantly different.\\n'"
      ]
     },
     "execution_count": 1,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "\n",
    "import numpy as np\n",
    "import scipy.stats as stats\n",
    "\n",
    "# Data for Profession A and B\n",
    "profession_A = [48, 52, 55, 60, 62]\n",
    "profession_B = [45, 50, 55, 52, 47]\n",
    "\n",
    "# Calculate variances\n",
    "var_A = np.var(profession_A, ddof=1)\n",
    "var_B = np.var(profession_B, ddof=1)\n",
    "\n",
    "# Calculate F-statistic\n",
    "F_statistic = var_A / var_B\n",
    "df1 = len(profession_A) - 1\n",
    "df2 = len(profession_B) - 1\n",
    "\n",
    "# Calculate p-value\n",
    "p_value = stats.f.sf(F_statistic, df1, df2)\n",
    "\n",
    "# Results\n",
    "print(\"F-statistic:\", F_statistic)\n",
    "print(\"p-value:\", p_value)\n",
    "\"\"\"\n",
    "Interpretation:\n",
    "- If the p-value < 0.05 (common significance level), reject the null hypothesis that the variances are equal.\n",
    "- Otherwise, fail to reject the null hypothesis, implying variances are not significantly different.\n",
    "\"\"\"\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 9. One-way ANOVA for testing differences in average heights across three regions."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "F-statistic: 67.87330316742101\n",
      "p-value: 2.870664187937026e-07\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "'\\nInterpretation:\\n- If the p-value < 0.05, conclude there are significant differences among group means.\\n- Otherwise, fail to reject the null hypothesis, implying no significant difference in means.\\n'"
      ]
     },
     "execution_count": 2,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "### Answer\n",
    "import scipy.stats as stats\n",
    "\n",
    "# Data for three regions\n",
    "region_A = [160, 162, 165, 158, 164]\n",
    "region_B = [172, 175, 170, 168, 174]\n",
    "region_C = [180, 182, 179, 185, 183]\n",
    "\n",
    "# Perform one-way ANOVA\n",
    "F_statistic, p_value = stats.f_oneway(region_A, region_B, region_C)\n",
    "\n",
    "# Results\n",
    "print(\"F-statistic:\", F_statistic)\n",
    "print(\"p-value:\", p_value)\n",
    "\"\"\"\n",
    "Interpretation:\n",
    "- If the p-value < 0.05, conclude there are significant differences among group means.\n",
    "- Otherwise, fail to reject the null hypothesis, implying no significant difference in means.\n",
    "\"\"\"\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "base",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
